name: Spot Test Parity Example

# This is an example workflow for integrating Random Parity Spot Testing
# into your CI/CD pipeline. Customize as needed for your project.

on:
  # Run on pushes to main branches
  push:
    branches: [ main, develop, master ]
  
  # Run on pull requests
  pull_request:
    branches: [ main, develop, master ]
  
  # Allow manual triggering
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Test mode to run'
        required: false
        default: 'standard'
        type: choice
        options:
          - quick
          - standard
          - thorough
      command_count:
        description: 'Number of commands to execute'
        required: false
        default: '50'
        type: string
      seed:
        description: 'Random seed for reproducible testing'
        required: false
        type: string

jobs:
  spot-test-parity:
    name: Random Parity Spot Test
    runs-on: ubuntu-latest
    
    # Set timeout to prevent hanging builds
    timeout-minutes: 10
    
    strategy:
      matrix:
        # Test with different Node.js versions if needed
        node-version: [18, 20]
        # Test different modes for comprehensive coverage
        test-mode: [quick, standard]
        exclude:
          # Avoid redundant combinations
          - node-version: 20
            test-mode: quick
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # Fetch full history for better context
          fetch-depth: 0
      
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
          cache-dependency-path: package-lock.json
      
      - name: Install dependencies
        run: |
          npm ci
          # Install additional dependencies if needed
          # npm install --save-dev @types/node
      
      - name: Install Z-Machine interpreter
        run: |
          sudo apt-get update
          sudo apt-get install -y frotz
          # Verify installation
          frotz -h || echo "Frotz installed but help not available"
      
      - name: Verify game file exists
        run: |
          if [ ! -f "reference/COMPILED/zork1.z3" ]; then
            echo "Error: Game file reference/COMPILED/zork1.z3 not found"
            exit 1
          fi
          echo "Game file verified: $(ls -la reference/COMPILED/zork1.z3)"
      
      - name: Run TypeScript compilation check
        run: |
          # Ensure TypeScript code compiles before testing
          npx tsc --noEmit
      
      - name: Run spot test (Matrix Mode)
        if: github.event_name != 'workflow_dispatch'
        run: |
          case "${{ matrix.test-mode }}" in
            quick)
              npx tsx scripts/spot-test-parity.ts --quick --threshold 90 --output json --verbose
              ;;
            standard)
              npx tsx scripts/spot-test-parity.ts --ci --threshold 95 --output json --verbose
              ;;
            thorough)
              npx tsx scripts/spot-test-parity.ts --thorough --threshold 98 --output json --verbose
              ;;
          esac
        env:
          # Set environment variables for consistent testing
          SPOT_TEST_VERBOSE: true
          NODE_ENV: test
      
      - name: Run spot test (Manual Mode)
        if: github.event_name == 'workflow_dispatch'
        run: |
          ARGS="--${{ github.event.inputs.test_mode }} --output json --verbose"
          
          if [ -n "${{ github.event.inputs.command_count }}" ]; then
            ARGS="$ARGS --commands ${{ github.event.inputs.command_count }}"
          fi
          
          if [ -n "${{ github.event.inputs.seed }}" ]; then
            ARGS="$ARGS --seed ${{ github.event.inputs.seed }}"
          fi
          
          echo "Running: npx tsx scripts/spot-test-parity.ts $ARGS"
          npx tsx scripts/spot-test-parity.ts $ARGS
      
      - name: Parse test results
        if: always()
        id: test-results
        run: |
          # Extract key metrics from JSON output (if available)
          if [ -f "spot-test-results.json" ]; then
            PARITY_SCORE=$(jq -r '.summary.parityScore // "unknown"' spot-test-results.json)
            DIFFERENCES=$(jq -r '.summary.differencesFound // "unknown"' spot-test-results.json)
            RECOMMEND_DEEP=$(jq -r '.summary.recommendDeepAnalysis // false' spot-test-results.json)
            
            echo "parity-score=$PARITY_SCORE" >> $GITHUB_OUTPUT
            echo "differences-found=$DIFFERENCES" >> $GITHUB_OUTPUT
            echo "recommend-deep-analysis=$RECOMMEND_DEEP" >> $GITHUB_OUTPUT
          fi
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: spot-test-results-node${{ matrix.node-version }}-${{ matrix.test-mode }}
          path: |
            spot-test-results.json
            *.log
          retention-days: 30
      
      - name: Comment on PR (if applicable)
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const parityScore = '${{ steps.test-results.outputs.parity-score }}';
            const differences = '${{ steps.test-results.outputs.differences-found }}';
            const recommendDeep = '${{ steps.test-results.outputs.recommend-deep-analysis }}';
            
            let status = '✅ PASSED';
            let color = 'green';
            
            if (recommendDeep === 'true') {
              status = '⚠️ ISSUES DETECTED';
              color = 'orange';
            }
            
            if (parseFloat(parityScore) < 90) {
              status = '❌ FAILED';
              color = 'red';
            }
            
            const body = `## Spot Test Results (Node ${{ matrix.node-version }}, ${{ matrix.test-mode }} mode)
            
            **Status:** ${status}
            **Parity Score:** ${parityScore}%
            **Differences Found:** ${differences}
            **Deep Analysis Recommended:** ${recommendDeep}
            
            ${recommendDeep === 'true' ? '⚠️ Consider running comprehensive parity tests for detailed analysis.' : ''}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
      
      - name: Set job status
        if: always()
        run: |
          PARITY_SCORE="${{ steps.test-results.outputs.parity-score }}"
          
          if [ "$PARITY_SCORE" != "unknown" ]; then
            # Convert to integer for comparison
            PARITY_INT=$(echo "$PARITY_SCORE" | cut -d. -f1)
            
            case "${{ matrix.test-mode }}" in
              quick)
                THRESHOLD=90
                ;;
              standard)
                THRESHOLD=95
                ;;
              thorough)
                THRESHOLD=98
                ;;
              *)
                THRESHOLD=95
                ;;
            esac
            
            if [ "$PARITY_INT" -lt "$THRESHOLD" ]; then
              echo "❌ Spot test failed: $PARITY_SCORE% < $THRESHOLD%"
              exit 1
            else
              echo "✅ Spot test passed: $PARITY_SCORE% >= $THRESHOLD%"
            fi
          else
            echo "⚠️ Could not determine parity score"
            exit 1
          fi

  # Aggregate results from all matrix jobs
  spot-test-summary:
    name: Spot Test Summary
    runs-on: ubuntu-latest
    needs: spot-test-parity
    if: always()
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: test-results
      
      - name: Generate summary report
        run: |
          echo "# Spot Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Process all result files
          for result_file in test-results/*/spot-test-results.json; do
            if [ -f "$result_file" ]; then
              echo "Processing: $result_file"
              
              # Extract artifact name to determine test configuration
              artifact_name=$(basename $(dirname "$result_file"))
              
              # Parse results
              parity=$(jq -r '.summary.parityScore // "N/A"' "$result_file")
              differences=$(jq -r '.summary.differencesFound // "N/A"' "$result_file")
              recommend=$(jq -r '.summary.recommendDeepAnalysis // false' "$result_file")
              
              # Determine status
              if [ "$recommend" = "true" ]; then
                status="⚠️ Issues"
              elif [ "$parity" != "N/A" ] && [ "$(echo "$parity < 95" | bc -l)" = "1" ]; then
                status="❌ Failed"
              else
                status="✅ Passed"
              fi
              
              echo "| $artifact_name | $status | $parity% | $differences |" >> $GITHUB_STEP_SUMMARY
            fi
          done
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Legend:**" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Passed: Parity above threshold, no issues detected" >> $GITHUB_STEP_SUMMARY
          echo "- ⚠️ Issues: Parity acceptable but issues detected" >> $GITHUB_STEP_SUMMARY
          echo "- ❌ Failed: Parity below threshold" >> $GITHUB_STEP_SUMMARY
      
      - name: Check overall status
        run: |
          # Determine if any tests failed
          FAILED=false
          
          for result_file in test-results/*/spot-test-results.json; do
            if [ -f "$result_file" ]; then
              parity=$(jq -r '.summary.parityScore // 0' "$result_file")
              if [ "$(echo "$parity < 90" | bc -l)" = "1" ]; then
                FAILED=true
                break
              fi
            fi
          done
          
          if [ "$FAILED" = "true" ]; then
            echo "❌ One or more spot tests failed"
            exit 1
          else
            echo "✅ All spot tests passed"
          fi

  # Optional: Trigger comprehensive tests if spot tests detect issues
  trigger-comprehensive-tests:
    name: Trigger Comprehensive Tests
    runs-on: ubuntu-latest
    needs: spot-test-parity
    if: contains(needs.spot-test-parity.outputs.recommend-deep-analysis, 'true')
    
    steps:
      - name: Trigger comprehensive test workflow
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'comprehensive-tests.yml',
              ref: context.ref,
              inputs: {
                triggered_by: 'spot-test-issues',
                priority: 'high'
              }
            });
            
            console.log('Triggered comprehensive tests due to spot test issues');

# Example of how to use this workflow:
#
# 1. Copy this file to .github/workflows/ in your repository
# 2. Customize the branches, Node.js versions, and test modes as needed
# 3. Adjust thresholds based on your project's requirements
# 4. Add any additional setup steps specific to your environment
# 5. Configure notifications and integrations as needed
#
# The workflow will:
# - Run spot tests on multiple Node.js versions and test modes
# - Generate detailed reports and summaries
# - Comment on pull requests with results
# - Upload artifacts for later analysis
# - Optionally trigger comprehensive tests if issues are detected